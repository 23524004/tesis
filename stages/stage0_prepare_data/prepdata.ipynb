{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f27cce65-9e1f-41fd-98a9-a8284b1eb838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataRaw = '../datasets/CSARXIV.parquet.gzip'\n",
    "df = pd.read_parquet( dataRaw , engine = 'fastparquet')\n",
    "n=100\n",
    "\n",
    "df = df[[\"Abstract\"]].sample(n, random_state=42)\n",
    "df[:3]\n",
    "print(len(df))\n",
    "# df = df.sample(n, random_state=42)[\"Abstract\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36e62526-413c-4c2b-881e-f77059f824d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 → 99\n",
      "The availability of large scale databases containing imaging and non-imaging data, such as the UK Biobank, represents an opportunity to improve our understanding of healthy and diseased bodily function. Cardiac motion atlases provide a space of reference in which the motion fields of a cohort of subjects can be directly compared. In this work, a cardiac motion atlas is built from cine MR data from the UK Biobank (~ subjects). Two automated quality control strategies are proposed to reject subjects with insufficient image quality. Based on the atlas, three dimensionality reduction algorithms are evaluated to learn data-driven cardiac motion descriptors, and statistical methods used to study the association between these descriptors and non-imaging data. Results show a positive correlation between the atlas motion descriptors and body fat percentage, basal metabolic rate, hypertension, smoking status and alcohol intake frequency. The proposed method outperforms the ability to identify changes in cardiac function due to these known cardiovascular risk factors compared to ejection fraction, the most commonly used descriptor of cardiac function. In conclusion, this work represents a framework for further investigation of the factors influencing cardiac health.\n"
     ]
    }
   ],
   "source": [
    "from prepdata import ArxivPreprocessor\n",
    "\n",
    "preprocessor = ArxivPreprocessor()\n",
    "\n",
    "df_clean = preprocessor.preprocess_dataframe(\n",
    "    df,\n",
    "    text_col=\"Abstract\"\n",
    ")\n",
    "\n",
    "print(len(df), \"→\", len(df_clean))\n",
    "print(df_clean[\"Abstract\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc87c113-ad60-4395-97fb-aaf02dec0c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 → 99\n",
      "The availability of large scale databases containing imaging and non-imaging data, such as the UK Biobank, represents an opportunity to improve our understanding of healthy and diseased bodily function. Cardiac motion atlases provide a space of reference in which the motion fields of a cohort of subjects can be directly compared. In this work, a cardiac motion atlas is built from cine MR data from the UK Biobank ( subjects). Two automated quality control strategies are proposed to reject subjects with insufficient image quality. Based on the atlas, three dimensionality reduction algorithms are evaluated to learn data-driven cardiac motion descriptors, and statistical methods used to study the association between these descriptors and non-imaging data. Results show a positive correlation between the atlas motion descriptors and body fat percentage, basal metabolic rate, hypertension, smoking status and alcohol intake frequency. The proposed method outperforms the ability to identify changes in cardiac function due to these known cardiovascular risk factors compared to ejection fraction, the most commonly used descriptor of cardiac function. In conclusion, this work represents a framework for further investigation of the factors influencing cardiac health.\n"
     ]
    }
   ],
   "source": [
    "from prepdata import ArxivPreprocessor\n",
    "\n",
    "preprocessor = ArxivPreprocessor()\n",
    "\n",
    "df_clean = preprocessor.preprocess_dataframe(\n",
    "    df,\n",
    "    text_col=\"Abstract\"\n",
    ")\n",
    "\n",
    "print(len(df), \"→\", len(df_clean))\n",
    "print(df_clean[\"Abstract\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07390557-0714-47b7-aca5-b717ec0a2ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a20ae485-f61c-42ee-a3f2-1b5e820ce807",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv('df_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f7c7a7-f23c-444d-bd2a-961aa47f76bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b48ca59-c8ae-4364-995e-c6d579a1670e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABSTRAK WITH MOST UNNATURAL\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Markup_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This paper shows that  \\mathbf P  = \\mathbf NP...</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For an undirected, simple, finite, connected g...</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For an undirected, simple, finite, connected g...</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>For an undirected, simple, finite, connected g...</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Determining deep holes is an important topic i...</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>It has been an active research issue for many ...</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>We show that given an estimate  \\widehat A   t...</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The dynamically defined measure (DDM)  \\Phi  a...</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A set  S\\subseteq V  is \\textit independent  i...</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>In the classical best arm identification (Best...</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Abstract  Markup_Count\n",
       "0  This paper shows that  \\mathbf P  = \\mathbf NP...           269\n",
       "1  For an undirected, simple, finite, connected g...           212\n",
       "2  For an undirected, simple, finite, connected g...           211\n",
       "3  For an undirected, simple, finite, connected g...           205\n",
       "4  Determining deep holes is an important topic i...           204\n",
       "5  It has been an active research issue for many ...           186\n",
       "6  We show that given an estimate  \\widehat A   t...           184\n",
       "7  The dynamically defined measure (DDM)  \\Phi  a...           179\n",
       "8  A set  S\\subseteq V  is \\textit independent  i...           168\n",
       "9  In the classical best arm identification (Best...           165"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ABSTRAK WITH LEAST UNNATURAL\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Markup_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We report on a series of experiments in which ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Information extraction is the task of automati...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OPUS is a branch and bound search algorithm th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Characteristic models are an alternative, mode...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We introduce an algorithm for combinatorial se...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>An important problem in geometric reasoning is...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>We argue that the analysis of agent environmen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This paper combines two important directions o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Starting with a likelihood or preference order...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>It is odd that chess grandmasters often disagr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Abstract  Markup_Count\n",
       "0  We report on a series of experiments in which ...             0\n",
       "1  Information extraction is the task of automati...             0\n",
       "2  OPUS is a branch and bound search algorithm th...             0\n",
       "3  Characteristic models are an alternative, mode...             0\n",
       "4  We introduce an algorithm for combinatorial se...             0\n",
       "5  An important problem in geometric reasoning is...             0\n",
       "6  We argue that the analysis of agent environmen...             0\n",
       "7  This paper combines two important directions o...             0\n",
       "8  Starting with a likelihood or preference order...             0\n",
       "9  It is odd that chess grandmasters often disagr...             0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Google Drive direct download link\n",
    "top_10_most_unnatural = 'https://drive.google.com/uc?export=download&id=1_rlJP9gqVtymS35ysJFBApJcclDm2Cpm'\n",
    "top_10_least_unnatural = 'https://drive.google.com/uc?export=download&id=1JEH5fsWGjDRfANxoRCISpzkX27pbWRUU'\n",
    "\n",
    "# Read the Excel file directly into a pandas DataFrame\n",
    "df_top_most_unnatural = pd.read_excel(top_10_most_unnatural)\n",
    "df_top_least_unnatural = pd.read_excel(top_10_least_unnatural)\n",
    "\n",
    "# Display the first 5 rows of the DataFrame\n",
    "print('ABSTRAK WITH MOST UNNATURAL')\n",
    "display(df_top_most_unnatural)\n",
    "\n",
    "print('\\n\\nABSTRAK WITH LEAST UNNATURAL')\n",
    "display(df_top_least_unnatural)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602f2e81-a7e3-4783-9b5a-589c36b405aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_abstract_text(text):\n",
    "    # Convert to string to handle potential non-string types\n",
    "    text = str(text)\n",
    "\n",
    "    # 1. Remove LaTeX math environments (e.g., $...$ or $$...$$)\n",
    "    text = re.sub(r'\\$.*?\\$', '', text) # Inline math\n",
    "    text = re.sub(r'\\$\\$.*?\\$\\$', '', text) # Display math\n",
    "\n",
    "    # 2. Remove common LaTeX commands (e.g., \\begin, \\end, \\section, \\ref, etc.)\n",
    "    text = re.sub(r'\\\\(.*?){.*?}', '', text) # Commands with arguments like \\command{arg}\n",
    "    text = re.sub(r'\\\\\\w+', '', text)        # Commands without arguments like \\newline\n",
    "\n",
    "    # 3. Remove numbers, but preserve 4-digit numbers (potential years)\n",
    "    # This regex removes:\n",
    "    # - Floating point numbers (e.g., 98.7, 0.01, 3.2)\n",
    "    # - Standalone numbers that are 1-3 digits long (e.g., 5, 10, 100)\n",
    "    # - Standalone numbers that are 5 or more digits long (e.g., 12345)\n",
    "    # This specifically leaves 4-digit numbers (like 2020) untouched if they are standalone.\n",
    "    text = re.sub(r'\\b(?:\\d{1,3}|\\d{5,})\\b|\\d+\\.\\d+', ' ', text)\n",
    "\n",
    "    # 4. Remove special characters and punctuation (keep letters, spaces, and now also digits)\n",
    "    # We allow digits here, as we've already selectively removed non-year numbers in the previous step.\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "\n",
    "    # 5. Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # 6. Remove words that are 1 or 2 characters long\n",
    "    text = ' '.join([word for word in text.split() if len(word) > 2])\n",
    "\n",
    "    # 7. Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "# df_top_most_unnatural['cleaned_abstract'] = df_top_most_unnatural['Abstract'].apply(clean_abstract_text)\n",
    "# print(\"Abstracts cleaned and stored in 'cleaned_abstract' column.\")\n",
    "# display(df_top_most_unnatural[['Abstract', 'cleaned_abstract']].sample(5))\n",
    "\n",
    "\n",
    "\n",
    "### RESULT DF BEFORE - AFTER\n",
    "### MOST UNNATURAL\n",
    "\n",
    "df_top_most_unnatural['cleaned_abstract'] = df_top_most_unnatural['Abstract'].apply(clean_abstract_text)\n",
    "display(df_top_most_unnatural[['Abstract', 'cleaned_abstract']])\n",
    "\n",
    "### RESULT DF BEFORE - AFTER\n",
    "### LEAST UNNATURAL\n",
    "\n",
    "df_top_least_unnatural['cleaned_abstract'] = df_top_least_unnatural['Abstract'].apply(clean_abstract_text)\n",
    "display(df_top_least_unnatural[['Abstract', 'cleaned_abstract']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29ac7332-19f7-4cb9-9cb8-205d33a8fa2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 → 10\n",
      "This paper shows that  \\mathbf P  = \\mathbf NP   by means of one-in-three SAT, also known as exactly- SAT, or XSAT.  \\phi = \\bigwedge C_k  denotes an XSAT formula,  C_k = (r_i \\odot r_j \\odot r_u)  is a clause, and  \\phi(r_j) := r_j \\wedge \\phi  denotes the truth assignment  r_j = \\mathbf T  ,  r_j \\in \\ x_j, \\overline x _j\\  . The assignment initiates reductions via  \\odot  of  C_k = (r_j \\odot \\overline x _i \\odot x_u)  into  \\psi_k = r_j \\wedge x_i \\wedge \\overline x _u  for all  C_k \\ni r_j , and  C_k = (\\overline r _j \\odot r_u \\odot r_v)  into  C_ k'  = (r_u \\odot r_v)  for all  C_k \\ni \\overline r _j . These reductions transform  r_j \\wedge \\phi  into  \\psi(r_j) \\wedge \\phi'(r_j) , unless  \\psi(r_j)  involves a contradiction  x_i \\wedge \\overline x _i . Then,  \\phi'(r_j) = \\bigwedge (C_k \\wedge C_ k' ) , and  \\psi(r_j) = \\bigwedge (\\psi_k \\wedge C_ k' )  such that  C_ k'  = r_i , thus  \\psi(r_j)  and  \\phi'(r_j)  are disjoint. Also,  \\psi(r_j)  involves  x_i \\wedge \\overline x _i  iff  \\not\\models \\psi(r_j) , which is trivial to verify. Furthermore, it is redundant to check if  \\not\\models \\phi'(r_j) , sketched out as follows. Any  \\psi(r_i)  is true,  \\psi(r_i) \\models \\psi(r_i | r_j) , hence  \\psi(r_i | r_j)  is true for all  r_i  in  \\phi'(r_j) , which becomes satisfiable when any  r_j  such that  \\not\\models \\psi(r_j)  is removed from  \\phi , hence any  \\overline r _j  is in  \\psi . Thus,  \\phi  transforms into  \\psi \\wedge \\phi' , where  \\psi = \\bigwedge r_i . If  \\psi \\supseteq \\ x_j, \\overline x _j\\  , then  \\not\\models \\phi , or else  \\phi(r_i) = \\psi(r_i) \\wedge \\phi'(r_i)  reduces to  \\psi(r_i)  and  \\psi \\wedge \\psi(r_ i_ ) \\wedge \\psi(r_ i_  | r_ i_ ) \\wedge \\cdots \\wedge \\psi(r_ i_n  | r_ i_m )  satisfies  \\phi , and any  \\psi(r_j | r_i)  and  \\psi(r_k | r_j)  are disjoint. The time complexity is  O(mn ) , therefore  \\mathbf P  = \\mathbf NP  .\n",
      "\n",
      "This paper shows that P NP by means of one_in_three sat_problem , also known as exactly- sat_problem , or xsat_problem . C_k denotes an xsat_problem formula, C_k (r_i r_j r_u) is a clause, and (r_j) : r_j denotes the truth assignment r_j T , r_j \\ x_j, x _j\\ . The assignment initiates reductions via of C_k (r_j x _i x_u) into _k r_j x_i x _u for all C_k r_j , and C_k ( r _j r_u r_v) into C_ k' (r_u r_v) for all C_k r _j . These reductions transform r_j into (r_j) '(r_j) , unless (r_j) involves a contradiction x_i x _i . Then, '(r_j) (C_k C_ k' ) , and (r_j) ( _k C_ k' ) such that C_ k' r_i , thus (r_j) and '(r_j) are disjoint. Also, (r_j) involves x_i x _i iff (r_j) , which is trivial to verify. Furthermore, it is redundant to check if '(r_j) , sketched out as follows. Any (r_i) is true, (r_i) (r_i | r_j) , hence (r_i | r_j) is true for all r_i in '(r_j) , which becomes satisfiable when any r_j such that (r_j) is removed from , hence any r _j is in . Thus, transforms into ' , where r_i . If \\ x_j, x _j\\ , then , or else (r_i) (r_i) '(r_i) reduces to (r_i) and (r_ i_ ) (r_ i_ | r_ i_ ) (r_ i_n | r_ i_m ) satisfies , and any (r_j | r_i) and (r_k | r_j) are disjoint. The time complexity is time_complexity , therefore P NP .\n"
     ]
    }
   ],
   "source": [
    "from prepdata import ArxivPreprocessor\n",
    "\n",
    "prep = ArxivPreprocessor()\n",
    "\n",
    "df_clean = prep.preprocess_dataframe(\n",
    "    df_top_most_unnatural,\n",
    "    text_col=\"Abstract\"\n",
    ")\n",
    "\n",
    "print(len(df_top_most_unnatural), \"→\", len(df_clean))\n",
    "print(df_top_most_unnatural[\"Abstract\"].iloc[0])\n",
    "print()\n",
    "print(df_clean[\"Abstract\"].iloc[0])\n",
    "\n",
    "df_top_most_unnatural.to_csv('df.csv', index=False)\n",
    "df_clean.to_csv('df_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf5c5f6a-c0d3-426c-b2b8-0f37c106b628",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c9be2d9-1adb-4c0a-8610-736ef1923547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 → 10\n",
      "We report on a series of experiments in which all decision trees consistent with the training data are constructed. These experiments were run to gain an understanding of the properties of the set of consistent decision trees and the factors that affect the accuracy of individual trees. In particular, we investigated the relationship between the size of a decision tree consistent with some training data and the accuracy of the tree on test data. The experiments were performed on a massively parallel Maspar computer. The results of the experiments on several artificial and two real world problems indicate that, for many of the problems investigated, smaller consistent decision trees are on average less accurate than the average accuracy of slightly larger trees.\n",
      "\n",
      "We report on a series of experiments in which all decision trees consistent with the training data are constructed. These experiments were run to gain an understanding of the properties of the set of consistent decision trees and the factors that affect the accuracy of individual trees. In particular, we investigated the relationship between the size of a decision tree consistent with some training data and the accuracy of the tree on test data. The experiments were performed on a massively parallel Maspar computer. The results of the experiments on several artificial and two real world problems indicate that, for many of the problems investigated, smaller consistent decision trees are on average less accurate than the average accuracy of slightly larger trees.\n"
     ]
    }
   ],
   "source": [
    "from prepdata import ArxivPreprocessor\n",
    "\n",
    "prep = ArxivPreprocessor()\n",
    "\n",
    "df_clean = prep.preprocess_dataframe(\n",
    "    df_top_least_unnatural,\n",
    "    text_col=\"Abstract\"\n",
    ")\n",
    "\n",
    "print(len(df_top_least_unnatural), \"→\", len(df_clean))\n",
    "print(df_top_least_unnatural[\"Abstract\"].iloc[0])\n",
    "print()\n",
    "print(df_clean[\"Abstract\"].iloc[0])\n",
    "\n",
    "\n",
    "df_top_least_unnatural.to_csv('df.csv', index=False)\n",
    "df_clean.to_csv('df_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315346fb-0ba0-4a9d-bdde-677c7322f5ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9a71dc-6001-4b47-ba85-f8dc3ecd5709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05bd6ae5-1fdb-4f8a-a383-6f943905bd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1975\n",
      "1975\n",
      "509      |Hi, everybody:\\n |    I guess my subject has...\n",
      "645     [reply to mcovingt@aisun3.ai.uga.edu (Michael ...\n",
      "1903    I have the same problem with a Diamond Stealth...\n",
      "397     : Yes, a lot of what OS/2 2.0 has in common wi...\n",
      "1809    \\n- They invented the \"how to make money on ot...\n",
      "1688    \\n\\n\\nARGHHHHHHHHHh\\n\\nREAD THE MEMOS!!!!\\n\\nI...\n",
      "Name: text, dtype: object\n",
      "\n",
      "I am ordering the Actix graphicsengine ultra plus. It is the same price\n",
      "as the stealth card. Plus it is also based on S3 928 chip the newest and\n",
      "fastest chip from s3. \n",
      "Everyone, if you are looking for a card, SEE THE APRIL ISSUE OF PC MAGAZINE\n",
      "FOR THEIR REVIEW.  \n",
      "They noted this person's problem with dos. The stealth card is not a very good\n",
      "dos performer. The Actix card is rated the best in this chip class (non local\n",
      "bus). It got glowing reports from the magazine (was a best buy) and I called\n",
      "them directly and they just updated their windows drivers last week! They have\n",
      "a bulletin board to get the latest drivers. \n",
      "Though somone posted that this bbs was at 2400. \n",
      "\n",
      "AT any rate, the Actix graphics engine ultra outperforms all the other cards\n",
      "in the 928 class (based on the winmark results).\n",
      "\n",
      "If you are looking for the all around best dos/windows performance  check out\n",
      "the actix card. Their 1-800 number is 927-5557.\n",
      "\n",
      "P.S. The article in pc magazine noted that if you are a regular dos user (ie:\n",
      "games) then you should also check out the 801 chip from s3. It apparently\n",
      "scores just as well and in many cases slightly better in dos than the 928 chip\n",
      "(ie: stealth and actix cards.) They have \"comparable\" windows performance and\n",
      "are cheaper to buy.\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# categories = ['sci.med', 'comp.os.ms-windows.misc']\n",
    "# data = fetch_20newsgroups(subset='all', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# docs = data.data\n",
    "# labels = data.target\n",
    "\n",
    "# print(len(docs))\n",
    "# print(len(labels))\n",
    "\n",
    "\n",
    "\n",
    "# import pandas as pd\n",
    "# from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# categories = ['sci.med', 'comp.os.ms-windows.misc']\n",
    "# newsgroups = fetch_20newsgroups(subset='all', categories=categories, \n",
    "#                                 remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# # 2. Masukkan ke DataFrame awal\n",
    "# df = pd.DataFrame({\n",
    "#     'text': newsgroups.data,\n",
    "#     'ground_truth': newsgroups.target,\n",
    "#     'target_names': [newsgroups.target_names[i] for i in newsgroups.target]\n",
    "# })\n",
    "\n",
    "# df.head()\n",
    "\n",
    "\n",
    "# print(df['text'].sample(6))\n",
    "\n",
    "# print(docs[270])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesis1",
   "language": "python",
   "name": "tesis1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
